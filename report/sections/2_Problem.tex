% НМФ
% - четко о постановке задачи,
% - описание реализованных методов (отдельный пункт для каждого метода + код),
% - о сходимости (см. статью))

\chapter{Неотрицательная матричная факторизация}





\section{Постановка задачи}

Задача неотрицательной матричной факторизации может быть сформулирована следующим образом:
для матрицы $A \in \RR^{m \times n}, A \geq 0$ и числа $k \in N, k < \min\{n, m\}$
необходимо найти  такие матрицы $W \in \RR^{m \times k}, H \in \RR^{k \times n} : W \geq 0, H \geq 0$ чтобы было верным приближенное равенство:
\begin{equation} \label{eq:problem}
  A \approx W H.
\end{equation}

Произведение $WH$ называется неотрицательной факторизацией матрицы $A$. Неравенства $A \geq 0$, $W \geq 0$, $H \geq 0$ означают что все элементы соответствующих матриц неотрицательны.
Качество приближения по формуле \eqref{eq:problem} можно оценить различными способами, такими как норма Фробениуса,
дивергенция Кульбака-Лейблера и некоторыми другими.

Дивергенция Кульбака-Лейблера:
\begin{equation*}
  f(W, H) =
    \sum_{i=1}^m \sum_{j=1}^n
    \left(
      A_{i,j} \
      ln\left(
        \frac{A_{i,j}}{(WH)_{i,j}}
      \right)
      - A_{i,j}
      + (WH)_{i,j}
    \right).
\end{equation*}

Норма Фробениуса:
\begin{equation*}
  f(W, H) = || A - WH ||^2_F.
\end{equation*}

Ниже будет использован несколько модифицированный вариант нормы Фробениуса,
который будем называть относительной погрешностью нормы Фробениуса:
\begin{equation} \label{eq:frob_norm}
  f(W, H) = \dfrac{||A - WH||_F}{|| A ||_F}.
\end{equation}

В идеальном случае, когда $f(W,H)=0$ матрица $A$ равна произведению $WH$.
На практике это далеко не всегда так, и почти всегда произведение $WH$ является приближенным разложением ранга не более $k$.

\newpage

Учитывая все вышесказанное задачу неотрицательной матричной факторизации можно сформулировать следующим образом:

\subsubsection{Задача неотрицательной матричной факторизации}

Для матрицы $A \in \RR^{m \times n}, A \geq 0$ и числа $k \in N, k < \min\{n, m\}$
необходимо найти матрицы $W \in \RR^{m \times k}, H \in \RR^{k \times n} : W \geq 0, H \geq 0$ минимизируя функционал:
\begin{equation} \label{eq:min_problem}
  \min_{W \geq 0, \ H \geq 0} \dfrac{||A - WH||_F}{|| A ||_F}.
\end{equation}

Задача \eqref{eq:min_problem} является невыпуклой задачей оптимизации относительно переменных $W$ и $H$,
и нахождение ее глобального минимума является NP-сложной задачей \cite{vavaris}.
Поэтому ожидается, что хороший алгоритм будет вычислять некоторый удовлетворительный локальный минимум задачи \eqref{eq:min_problem}.

Правильный выбор значения $k$ является критически важным для получения удовлетворительного результата,
но также выбор $k$ очень часто зависит от природы решаемой задачи и поставленного вопроса.
В большинстве случаев, $k$ обычно выбирают таким образом, чтобы $k \ll \min\{m, n\}$,
и в этом случае произведение $WH$ можно рассматривать как сжатую форму данных матрицы $A$.

Ключевой характеристикой неотрицательной матричной факторизации является возможность
использования численных методов для минимизации \eqref{eq:min_problem}
для извлечения некоторых базовых признаков в качестве базисных векторов матрицы $W​$,
которые затем могут быть использованы для поиска и классификации.
% Ограничивая матрицы $W​$ и $H​$ только неотрицательными элементами
% неотрицательная матричная факторизация позволяет представлять исходные данные из \textit{не вычитающих комбинаций}.
% Элементы таких комбинаций могут быть частями лиц в изображениях, темами или кластерами в текстовых данных
% или некоторыми другими характеристиками многомерных данных.

Одной их важных проблем, влияющих на численную минимизацию \eqref{eq:min_problem},
является существование локальных минимумов
из-за невыпуклости \eqref{eq:min_problem} как по $W$, так и по $H$.
Не менее важной проблемой является отсутствие единственного решения,
которое можно легко увидеть, рассматривая произведение $WDD^{− 1}H$ для любой неотрицательной обратимой матрицы $D$.

Несмотря на многие недостатки неотрицательная матричная факторизация весьма привлекательна для приложений интеллектуального анализа данных,
поскольку на практике даже локальные минимумы могут обеспечивать желаемые свойства, такие как сжатие данных и извлечение базовых признаков.





\newpage





\section{Методы решения задачи НМФ}

Существует множество различных способов решения задачи неотрицательной матричной факторизации.
Самыми популярными и наиболее исследованным являются: метод главных компонент, усеченное сингулярное разложение и методы неотрицательной матричной факторизации.
Стоит отметить что все вышеперечисленные методы решают задачу неотрицательной матричной факторизации,
однако название \textit{"метод неотрицательной матричной факторизации"} обычно применимо только к методам решающим задачу в формулировке \eqref{eq:min_problem}.
Ниже будут рассмотрены некоторые методы численного решения задачи неотрицательной матричной факторизации.

\subsubsection{Численные методы решения задачи}
Численные методы решения задачи неотрицательной матричной факторизации
могут быть поделены на следующие основные категории:
\begin{enumerate}
	\item Методы мультипликативного обновления
	\item Методы попеременных наименьших квадратов
	\item Методы градиентного спуска
\end{enumerate}

К методам мультипликативного обновления принадлежит классический метод мультипликативного обновления,
разработанный Lee и Seung \cite{lee_seung},
а также множество основанных на нём методов, улучшающих его сходимость.

К методам попеременных наименьших квадратов относится семейство методов,
использующих тот факт, что задача разрешима отдельно по каждой переменной.

К методам градиентного спуска относятся такие методы, как метод проецированного градиентного спуска \cite{lin} и другие.

В ходе работы были исследованы 2 категории методов: методы мультипликативного обновления и методы попеременных наименьших квадратов.
Далее будут подробнее рассмотрены самые распространенные методы из этих категорий.



\newpage



\subsection{Метод мультипликативного обновления}

Алгоритм был разработан Daniel D. Lee и H. Sebastian Seung в 2001 году.
Lee и Seung использовали градиент и свойства непрерывного спуска (точнее, непрерывного невозрастания),
чтобы утверждать, что данный алгоритм сходится к локальному минимуму.
Фактически, доказательство показывает свойство непрерывного спуска (невозрастания),
которое не исключает достижения только локального минимума.

\begin{algorithm}
  \BlankLine
  \BlankLine

  \Input{Неотрицательная матрица $A$}
  \Output{Неотрицательные матрицы $W$ и $H$}

  \BlankLine

  Инициализировать $W$ и $H$ как случайные плотные матрицы\;

  \While{не достигнут критерий останова} {
    Обновить $H$ значением $H * W^T A / (W^T W H + \epsilon)$\;
    Обновить $W$ значением $W * A H^T / (W H H^T + \epsilon)$\;
  }

  \BlankLine

  \caption{Алгоритм мультипликативного обновления}
\end{algorithm}

Добавление $\epsilon$ в каждом правиле обновления необходимо чтобы избежать деления на ноль.
Обозначение $*$ подразумевает покомпонентное умножение матриц.

Если исходные матрицы $W$ и $H$ неотрицательны, то эти матрицы остаются неотрицательными на протяжении всех итераций.
Это утверждение легко подтверждается опираясь на мультипликативную форму правил обновления.

Благодаря своему статусу первых известных алгоритмов неотрицательной матричной факторизации
алгоритмы мультипликативного обновления стали основой,
с которой сравниваются более новые алгоритмы.
Неоднократно было показано \cite{langville}, что данные алгоритмы медленно сходятся.
Они требуют намного больше итераций и являются более трудоёмкими, чем альтернативы, такие как алгоритмы градиентного спуска и попеременных наименьших квадратов.
Каждая итерация требует шести $O(n^3)$ матричных умножений полностью плотных матриц и шести $O(n^2)$ покомпонентных умножений матриц.
Тем не менее, хорошие реализации могут улучшить ситуацию.
Например, в правиле обновления для $W$, для которого требуется произведение $WHH^T$, сначала необходимо вычислить малое $k \times k$ произведение $HH^T$.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация алгоритма MU на python3]
  {../src/methods/multiplicative_update_rule.py}



\newpage



\subsection{Метод попеременных наименьших квадратов}

В этом методе за шагом наименьших квадратов следует другой шаг наименьших квадратов поочередно.
Впервые методы попеременных наименьших квадратов были использованы в работе Paatero \cite{paatero}.

Метод использует тот факт, что задача минимизации выражения \eqref{eq:min_problem} не является выпуклой относительно $W$ и $H$ одновременно,
но является выпуклой относительно $W$ или $H$ по отдельности.
Таким образом, для одной матрицы другая матрица может быть найдена решением простой задачи наименьших квадратов.

\begin{algorithm}
  \BlankLine
  \BlankLine

  \Input{Неотрицательная матрица $A$}
  \Output{Неотрицательные матрицы $W$ и $H$}

  \BlankLine

  Инициализировать  $W$ и $H$ как случайные плотные матрицы\;

  \While{не достигнут критерий останова} {
    Найти $H$ решая задачу $\displaystyle\min_H||WH - A||$\; \label{alg:line:lstsq_1}
    Спроецировать $H$ на неотрицательную область\;
    Найти $W$ решая задачу $\displaystyle\min_{W^T}||H^TW^T - A^T||$\; \label{alg:line:lstsq_2}
    Спроецировать $W$ на неотрицательную область\;
  }

  \BlankLine

  \caption{Алгоритм попеременных наименьших квадратов}
\end{algorithm}

% В приведенном выше алгоритме используется простейший метод сохранения неотрицательности:
% проецирование матрицы на неотрицательную область.

Здесь проецирование на неотрицательную область означает обнуление всех отрицательных элементов, полученных в результате
вычисления решения.

Эта простая техника также имеет несколько дополнительные преимуществ:
она способствует разреженности матрицы, а кроме того добавляет гибкости итерациям,
которая недоступна в других алгоритмах, особенно в алгоритмах мультипликативного обновления.
Одним из недостатков алгоритмов мультипликативного обновления является то,
что если элемент в $W$ или $H$ становится равным $0$,
то он будет оставаться равным $0$ на протяжении всех итераций.
Эта блокировка нулевых элементов является большим ограничением алгоритма,
что означает как только алгоритм начинает двигаться вниз по пути к фиксированной точке,
даже если это \say{плохая} фиксированная точка, алгоритм продолжит двигаться в направлении к этой точке.
Алгоритмы попеременных наименьших квадратов являются более гибкими,
позволяя итеративному процессу сойти с \say{плохого} пути.




\newpage




Существует множество различных реализаций метода наименьших квадратов.
Каждая реализация основывается на различном методе решения задачи наименьших квадратов.

Далее рассмотрены самые популярные и эффективные реализации метода попеременных наименьших квадратов.

\subsubsection{Метод нормальных уравнений}

Данный алгоритм является базовым из семейства алгоритмов попеременных наименьших квадратов.
Задач наименьших квадратов решается следующим способом.
Необходимо находить значения $W$ и $H$ на каждой итерации и приведённых ниже уравнений.
\begin{equation}
  W^T W H = W^T A,
\end{equation}
\begin{equation}
  H H^T W^T = H A^T.
\end{equation}


На практике алгоритм очень чувствителен к накапливанию вычислительной погрешности,
а также, хоть поддерживает работу с разреженными матрицами, имеет проблемы при работе с вырожденными матрицами.
Так как разреженные матрицы обычно имеют не полный, весьма маленький ранг,
велика вероятность того, что одна из матриц $W^TW$, $HH^T$ также будет не полного ранга.
Ситуации такого рода ведут к невозможности продолжения итерационного процесса.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация алгоритма ALS\_NORM на python3, firstline=32, lastline=53]
  {../src/methods/alternating_least_squares.py}

\newpage

\subsubsection{Метод LSQR}

Следующий метод полностью основан на классическом методе попеременных наименьших квадратов.
В метод внесены корректировки, устраняющие недостатки предшественника, такие как проблемы
с матрицами неполного ранга и накопление вычислительной погрешности.
Для решения задачи наименьших квадратов используется алгоритм LSQR \cite{lsqr}.
\begin{equation}
  \min_H||WH - A||_2,
\end{equation}
\begin{equation}
  \min_{W^T}||H^TW^T - A^T||_2.
\end{equation}

Вместо решения системы линейных алгебраических уравнений на каждом шаге,
метод решает задачу минимизации $\displaystyle\min_X||AX - B||_2$, где $A$, $B$ и $X$ - матрицы.
Это позволяет избежать вышеперечисленных проблем,
однако повышает вычислительную сложность алгоритма.
Также в методе присутствует описанный выше шаг проецирования матрицы
на неотрицательную область.
Стоит отметить, что данный шаг \say{портит} решение, но он необходим,
чтобы обеспечить неотрицательность искомого разложения.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\


\lstinputlisting
  [firstline=16, lastline=19]
  {../src/methods/alternating_least_squares.py}

\lstinputlisting
  [caption=Реализация алгоритма ALS\_LSQR на python3, firstline=64, lastline=73]
  {../src/methods/alternating_least_squares.py}



\newpage


\subsubsection{Метод попеременных неотрицательных наименьших квадратов}

Данный метод вносит свои корректировки в метод попеременных наименьших квадратов,
улучшающие его характеристики.
\begin{equation}
  \min_{H \geq 0}||WH - A||_2,
\end{equation}
\begin{equation}
  \min_{W^T \geq 0}||H^TW^T - A^T||_2.
\end{equation}

Вместо решения системы линейных алгебраических уравнений на каждом шаге,
данный метод решает задачу минимизации $\displaystyle\min_{X \geq 0}||AX - B||_2$, где $A$, $B$ и $X$ - матрицы.
Необходимо обратить внимание на то, что на матрицу $X$ накладывается ограничение неотрицательности,
что позволяет избежать применения шага проецирования матрицы неотрицательную область.
На практике это позволяет значительно повысить скорость сходимости,
однако влечёт за собой увеличение вычислительной сложности алгоритма.

Для решения задачи неотрицательных наименьших квадратов используется алгоритм, описанный в работе \cite{nnls}.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация алгоритма ALS\_NNLS на python3, firstline=55, lastline=61]
  {../src/methods/alternating_least_squares.py}





\newpage





\section{Алгоритм инициализации матриц $W$ и $H$}

Проблема изложенных алгоритмов неотрицательной матричной факторизации заключается в том,
что сходимость к глобальному минимуму не гарантируется.
Часто случается, что сходимость медленная и достигается неоптимальное приближение.

Эффективная процедура для вычисления хорошего начального приближения может быть основана на сингулярном разложении матрицы $A$.

\begin{algorithm}

  \BlankLine
  \BlankLine

  \Input{Неотрицательная матрица $A$}
  \Output{Неотрицательные матрицы $W$ и $H$}

  \BlankLine

  Инициализировать  $W$ и $H$ как случайные плотные матрицы\;
  Разложить $A$ на $U$, $\Sigma$, $V^T$ используя SVD\;
  Выбрать $u_1$ в качестве первого столбца $U$\;

  \For{$i$ \KwFrom 1 \KwTo $k$} {
    Вычислить $C$ как $u_i v_i^T$\;
    Спроецировать $C$ на неотрицательную область\;
    Разложить $C$ на $U^\prime$, $\Sigma^\prime$, $V^{\prime T}$ используя SVD\;
    Выбрать $u^\prime_1$ в качестве $i$-го столбца $U$\;
  }

  \BlankLine

  \caption{Алгоритм инициализации матриц $W$ и $H$}
\end{algorithm}

Пусть $A = U \Sigma V^T $ является сингулярным разложением \cite{demmel} для матрицы $A$,
тогда следует взять первый сингулярный вектор $u_1$ в качестве первого столбца в $W$.
Затем необходимо взять матрицу $C = u_2 v_2^T$ и заменить все её отрицательные элементы на ноль.
Так как $C$ теперь является неотрицательной матрицей, то известно, что первый сингулярный вектор этой матрицы также неотрицательный.
Кроме того, предполагая что это достаточно хорошее приближение $u_2$, возможно принять его за второй столбец $W$.
Продолжим процедуру далее, пока вся матрица $W$ не будет заполнена.

На практике метод даёт хороший прирост к сходимости,
однако с ростом размерности исходной матрицы его использование становится
нецелесообразным из-за большой вычислительной сложности.


\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\begin{lstlisting}[caption=Алгоритм SVD инициализации]
def initialize_svd(A):
  rows, columns = A.shape

  U, _, VT = svd_factorization(A, rank_k)

  W = U[:,:rank_k]
  H = random_matrix(rank_k, columns)

  for j in range(1, rank_k):
    C = reshape(U[:,j], (rows, 1)) @ reshape(VT[j,:], (1, columns))
    C = nonnegative(C)
    u, _, _ = svd_factorization(C, 1)

    W[:,j] = u[:,0]
  return W, H
\end{lstlisting}




\newpage





\section{Сходимость методов решения задачи}

В общем случае, метод неотрицательной матричной факторизации любого класса
должен ввести решение в условие оптимальности \cite{chu},
чтобы определить действительно ли это минимум.
Если решение подходит под условия оптимальности, то это означает, что достигнут как минимум локальный минимум.

На самом деле, задача неотрицательной матричной факторизации некорректно поставлена,
что означает отсутствие единственного глобального минимума.
Необходимо принять во внимание, что минимальное решение, заданное матрицами $W$ и $H$,
также может быть задано бесконечным числом одинаково хороших пар решений,
таких как $WD$ и $D^{-1}H$, для любых неотрицательных $D$ и $D^{−1}$.
Так как масштабирование и перестановка вызывают проблемы уникальности,
некоторые алгоритмы используют нормализацию строк или столбцов на каждой итерации.

Если в конкретном случае необходимо найти \say{достаточно хороший} локальный минимум,
то можно запустить алгоритм неотрицательной матричной факторизации с SVD инициализацией.

\subsubsection{Скорость сходимости}

Оценка скорости сходимости для этих алгоритмов является открытой нерешённой проблемой.
При определенных условиях возможно говорить о скоростях сходимости выбранных алгоритмов
или сравнивать относительные скорости сходимости между различными алгоритмами.

\subsubsection{Критерий останова}

Для выбора критерия останова необходимо получить оценки качества решения.
Поскольку сингулярное разложение ранга $k$, обозначаемое $U_k \Sigma_k V_k^T$,
обеспечивает нижнюю границу качества, решение должно как минимум удовлетворять следующему неравенству.
\begin{equation*}
  1 - \epsilon \leq \frac{||A - WH||_F}{||A - U_k \Sigma_k V_k^T||_F} \leq 1.
\end{equation*}

Где $\epsilon$ - небольшая положительная константа, зависящая от параметров
конкретного алгоритма неотрицательной матричной факторизации.

Вычисление погрешности $||A - WH||_F$ требует больших вычислительных затрат,
которые могут быть немного уменьшены при правильной реализации \cite{berry}:
% Следующее альтернативное выражение использует свойства нормы, для уменьшения вычислительных затрат.
\begin{equation} \label{eq:termination}
  ||A - WH||^2_F = \trace (A^T A) - 2 \trace(H^T (W^T A)) + \trace(H^T (W^T W H)).
\end{equation}

Данное выражение содержит эффективный порядок матричных произведений и позволяет
единожды произвести вычисления связанные с $\trace(A^T A)$.

Почти все алгоритмы неотрицательной матричной факторизации используют
максимальное количество итераций, как вторичный критерий останова.
Однако очевидно, что фиксированное количество итераций это не математически верный
подход для контроля итерационного процесса и максимальное количество итераций зависит от конкретной прикладной задачи.

Принимая во внимание всё вышесказанное и необходимость работы с разреженными данными,
воспользуемся следующим критерием останова:
\begin{equation} \label{eq:termination}
  |f(W_k, H_k) - f(W_{k-1}, H_{k-1})| \leq \epsilon,
\end{equation}
 где $f(W, H)$ - относительная погрешность \eqref{eq:frob_norm}.



\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация критерия останова, firstline=18, lastline=34]
  {../src/utils.py}
