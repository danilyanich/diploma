% НМФ
% - четко о постановке задачи,
% - описание реализованных методов (отдельный пункт для каждого метода + код),
% - о сходимости (см. статью))

\chapter{Неотрицательная матричная факторизация}





\section{Постановка задачи}

Задача неотрицательной матричной факторизации может быть сформулирована следующим образом:
Для матрицы $A \in R^{m \times n}, A \geq 0$ и числа $k \in N, k < min\{n, m\}$
необходимо найти  такие матрицы $W \in R^{m \times k}, H \in R^{k \times n} : W \geq 0, H \geq 0$ чтобы было верным приближенное равенство:
\begin{equation} \label{eq:problem}
  A \approx W H
\end{equation}

Произведение $WH$ называется неотрицательной факторизацией матрицы $A$. Неравенства $A \geq 0$, $W \geq 0$, $H \geq 0$ означают что все элементы соответсвующих матриц неотрицательны.
Качество приближения по формуле \ref{eq:problem} можно оценить различными способами, такими как норма Фробениуса,
дивергенция Кульбака-Лейблера и некоторыми другими.

Дивергенция Кульбака-Лейблера:
\begin{equation*}
  f(W, H) =
    \sum_{i=1}^m \sum_{j=1}^n
    \left(
      A_{i,j} \
      ln\left(
        \frac{A_{i,j}}{(WH)_{i,j}}
      \right)
      - A_{i,j}
      + (WH)_{i,j}
    \right)
\end{equation*}

Норма Фробениуса:
\begin{equation*}
  f(W, H) = || A - WH ||^2_F
\end{equation*}

Ниже будет исплользован несколько модифициронанный вариант нормы Фробениуса,
который называется относительной нормой Фробениуса:
\begin{equation} \label{eq:frob_norm}
  f(W, H) = \dfrac{||A - WH||_F}{|| A ||_F}
\end{equation}

В идеальном случае, когда $f(W,H)=0$ матрица $A$ равна произведению $WH$.
На практике это далеко не всегда так, и почти всегда произведение $WH$ является приближенным разложением ранга не более $k$.

\newpage

Учитывая все вышесказанное задачу неотрицательной матричной факторизации можно сформулировать следующим образом:

\subsubsection{Задача неотрицательной матричной факторизации}

Для матрицы $A \in R^{m \times n}, A \geq 0$ и числа $k \in N, k < min\{n, m\}$
необходимо найти матрицы $W \in R^{m \times k}, H \in R^{k \times n} : W \geq 0, H \geq 0$ минимизируя функционал:
\begin{equation} \label{eq:min_problem}
  \min_{W \leq 0, \ H \leq 0} \dfrac{||A - WH||_F}{|| A ||_F}
\end{equation}

Задача \ref{eq:min_problem} является невыпуклой задачей оптимизации относительно переменных $W$ и $H$,
и нахождение ее глобального минимума является NP-сложной задачей \cite{vavaris}.
Поэтому ожидается, что хороший алгоритм будет вычислять некоторый удовлетворительный локальный минимум задачи \ref{eq:min_problem}.






\section{Исследования задачи}

Правильный выбор значения $k$ является критически важным для получения удовлетворительного результата,
но также выбор $k$ очень часто зависит от природы решаемой задачи и поставленного вопроса.
В большинстве случаев, $k$ обычно выбирают таким образом, чтобы $k \ll min\{m, n\}$,
и в этом случае произведение $WH$ можно рассматривать как сжатую форму данных матрицы $A$.

Ключевой характеристикой неотрицательной матричной факторизации является возможность
использования численных методов для минимизации \ref{eq:min_problem}
для извлечения некоторых базовых признаков в качестве базисных векторов матрицы $W​$,
которые затем могут быть использованы для поиска и классификации.
Ограничивая матрицы $W​$ и $H​$ только неотрицательными элементами
неотрицательная матричная факторизация позволяет представлять исходные данные из \textit{не вычитающих комбинаций}.
Элементы таких комбинаций могут быть частями лиц в изображениях, темами или кластерами в текстовых данных
или некоторыми другими характеристиками многомерных данных.

Одной их важных проблем, влияющих на численную минимизацию \ref{eq:min_problem},
является существование локальных минимумов
из-за невыпуклости \ref{eq:min_problem} как по $W$, так и по $H$.
Не менее важной проблемой является отсутствие единственного решения,
которое можно легко увидеть рассматривая произведение $WDD^{− 1}H$ для любой неотрицательной обратимой матрицы $D$.

Несмотря на многие недостатки неотрицательная матричная факторизация весьма привлекательна для приложений интеллектуального анализа данных,
поскольку на практике даже локальные минимумы могут обеспечивать желаемые свойства, такие как сжатие данных и извлечение базовых признаков.





\newpage





\section{Методы решения задачи}

Существует множество различных способов решения задачи неотрицательной матричной факторизации.
Самыми популярными и наиболее исследоваными являются: метод главных компонент, усеченное сингулярное разложение и методы неотрицательной матричной факторизации.
Стоит отметить что все вышеперчисленные методы решают задачу неотрицательной матричной факторизации,
однако название \textit{"метод неотрицательной матричной факторизации"} обычно применимо только методам решающим задачу в формулировке \ref{eq:min_problem}.
Ниже будут рассмотрены некоторые методы численного решения задачи неотрицательной матричной факторизации.

\subsubsection{Численные методы решения задачи}
Численные методы решения задачи неотрицательной матричной факторизации
могут быть поделены на следующие основные категории:
\begin{enumerate}
	\item Методы мультипликативного обновления
	\item Методы попеременных наименьших квадратов
	\item Методы градиентного спуска
\end{enumerate}

К методам мультипликативного обновления принадлежит классический метод мультипликативного обновления,
разработанный Lee и Seung \cite{lee_seung},
а также множесто основанных на нём методов улучшающих его сходимость.

К методам попеременных наименьших квадратов относится множество методов,
использующих тот факт, что задача разрещима отдельно по каждой переменной.

К методам градиетного спуска относятся такие методы, как метод проецированного градиентного спуска \cite{lin} и другие.

В ходе работы были исследованы 2 категории методов: методы мультипликативного обновления и методы попеременных наименьших квадратов.
Далее будут подробнее рассмотрены самые распростанённые методы из этих категорий.



\newpage



\subsection{Метод мультипликативного обновления}

Алгоритм был разработан Daniel D. Lee и H. Sebastian Seung в 2001 году.
Lee и Seung использовали градиент и свойства непрерывного спуска (точнее, непрерывного невозрастания),
чтобы утверждать, что данный алгоритм сходится к локальному минимуму.
Фактически, доказательство показывает свойство непрерывного спуска (невозрастания),
которое не исключает достижения только локального минимума.

\begin{algorithm} \label{alg:mu}
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}

  \BlankLine
  \BlankLine

  \Input{Nonnegative matrix $A$}
  \Output{Nonnegative matrices $W$ и $H$}

  \BlankLine

  Initialize $W$ and $H$ as random dense matrices\;

  \While{stopping criteria is not reached} {
    Update $H$ with $H * W^T A / (W^T W H + \epsilon)$\;
    Update $W$ with $W * A H^T / (W H H^T + \epsilon)$\;
  }

  \BlankLine

  \caption{Алгоритм мультипликативного обновления}
\end{algorithm}

Добваление $\epsilon$ в каждом правиле обновления необходимо чтобы избежать деления на ноль.
Обозначение $*$ подразумевает покомпонентное умножение матриц.

Если исходные матрицы $W$ и $H$ неотрицательны, то эти матрицы остаются неотрицательными на протяжении всех итераций.
Это утверждение легко подтверждается опираясь на мультипликативную форму правил обновления.

Благодаря своему статусу первых известных алгоритмов неторицательной матричной факторизации
алгоритмы мультипликативного обновления стали основой,
с которой сравниваются более новые алгоритмы.
Неоднократно было показано \cite{langville}, что данные алгоритмы медленно сходятся.
Они требуют намного больше итераций, чем альтернативы, такие как алгоритмы градиентного спуска и попеременных наименьших квадратов, и работа на одну итерацию высока.
Каждая итерация требует шести $O(n^3)$ матричных умножений полностью плотных матриц и шести $O(n^2)$ покомпонентных умножений матриц.
Тем не менее, хорошие реализации могут улучшить ситуацию.
Например, в правиле обновления для $W$, для которого требуется произведение $WHH^T$, сначала необходимо вычислить малое $k \times k$ произведение $HH^T$.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация алгоритма MU на python3]
  {../src/methods/multiplicative_update_rule.py} \label{code:mu}



\newpage



\subsection{Классический метод попеременных наименьших квадратов}

В этом методе за шагом наименьших квадратов следует другой шаг наименьших квадратов поочередно.
Впервые методы попеременных наименьших квадратов были изпользованы Paatero \cite{paatero}.

Метод использует тот факт, что задача минимизации выражения \ref{eq:min_problem} не является выпуклой как в $W$,
так и в $H$ одновременно, но является выпуклой в $W$ или $H$ по отдельности.
Таким образом, для одной матрицы другая матрица может быть найдена простым решением системы линейных алгебраических уранений.

\begin{algorithm} \label{alg:als_solve}
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}

  \BlankLine
  \BlankLine

  \Input{Nonnegative matrix $A$}
  \Output{Nonnegative matrices $W$ и $H$}

  \BlankLine

  Initialize $W$ and $H$ as random dense matrices\;

  \While{stopping criteria is not reached} {
    Solve $H$ from $W^TWH=W^TA$\;
    Project $H$ to nonnegative space\;
    Solve $W^T$ from $HH^TW^T=HA^T$\;
    Project $W$ to nonnegative space\;
  }

  \BlankLine

  \caption{Алгоритм попеременных наименьших квадратов}
\end{algorithm}

В приведенном выше алгоритме ипользуется простейший метод сохранения неотрицательности:
проецирование матрицы на неотрицательную область.
На самом деле проецирование просто устанавливает все отрицательные элементы, полученные в результате
вычисления решения, в $0$.

Эта простая техника также имеет несколько дополнительные преимуществ:
она способствует разреженности матрицы, а кроме того добавляет гибкости итерациям,
которая недоступна в других алгоритмах, особенно в алгоритмах мультипликативного обновления.
Одним из недостатков алгоритмов мультипликативного обновления является то,
что если элемент в $W$ или $H$ становится равным $0$,
то он будет оставаться равным $0$ на протяжении всех итераций.
Эта блокировка нулевых элементов является большим ограничением алгоритма,
что означает как только алгоритм начинает двигаться вниз по пути к фиксированной точке,
даже если это \say{плохая} фиксированная точка, алгоритм продолжит двигаться в направлении к этой точке.
Алгоритмы попеременных наименьших квадратов являются более гибкими,
позволяя итеративному процессу сойти с \say{плохого} пути.

\newpage

Данный алгоритм является базовым из семейства алгоритмов попеременных наименьших квадратов.
На практике алгоритм очень чувствителен к накапливанию вычислительной погрешности,
а также, хоть поддерживает работу с разреженными матрицами, имеет проблемы при работе с вырожденными матрицами.
Так как разреженные матрицы обычно имеют не полный, весьма маленький ранг,
велика вероятность того, что одна из матриц $W^TW$, $HH^T$ также будет не полного ранга.
Ситуации такого рода ведут к невозможности продолжения итерационного процесса.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация алгоритма ALSS на python3, firstline=12, lastline=25]
  {../src/methods/alternating_least_squares.py} \label{code:als_solve}



\newpage



\subsection{Метод попеременных наименьших квадратов}

Следующий метод полностью основан на классическом методе попеременных наименьших квадратов.
В метод внесены корректировки, устраняющие недостаки предшественника, такие как проблемы
с матрицами неполного ранга и накопление вычислительной погрешности.


\begin{algorithm} \label{alg:als_lstsq}
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}

  \BlankLine
  \BlankLine

  \Input{Nonnegative matrix $A$}
  \Output{Nonnegative matrices $W$ и $H$}

  \BlankLine

  Initialize $W$ and $H$ as random dense matrices\;

  \While{stopping criteria is not reached} {
    Solve $H$ from $\displaystyle\min_H||W^TWH - W^TA||_2$\;
    Project $H$ to nonnegative space\;
    Solve $W^T$ from $\displaystyle\min_{W^T}||HH^TW^T - HA^T||_2$\;
    Project $W$ to nonnegative space\;
  }

  \BlankLine

  \caption{Алгоритм попеременных наименьших квадратов}
\end{algorithm}

Вместо решения системы линейных алгебраических уранений на каждом шаге,
метод решает задачу минимизации $\displaystyle\min_X||AX - B||_2$, где $A$, $B$ и $X$ - матрицы.
Это позволяет избежать вышеперечисленных проблем,
однако повышает вычислительную сложность алгоритма.
Также в методе присутсвует описанный выше шаг проецирования матрицы
на неотрицательную область.
Стоит отметить, что данный шаг \say{портит} решение, но он необходим,
чтобы обеспечить неотрицательность искомого разложения.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация алгоритма ALSTSQ на python3, firstline=52, lastline=70]
  {../src/methods/alternating_least_squares.py} \label{code:als_lstsq}



\newpage



\subsection{Метод попеременных неотрицательных наименьших квадратов}

Данный метод вносит свои корректировки в классический метод попеременных наименьших квадратов,
улучшающие его характеристики.


\begin{algorithm} \label{alg:als_nnls}
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}

  \BlankLine
  \BlankLine

  \Input{Nonnegative matrix $A$}
  \Output{Nonnegative matrices $W$ и $H$}

  \BlankLine

  Initialize $W$ and $H$ as random dense matrices\;

  \While{stopping criteria is not reached} {
    Solve $H$ from $\displaystyle\min_{H \leq 0}||W^TWH - W^TA||_2$\;
    Solve $W^T$ from $\displaystyle\min_{W^T \leq 0}||HH^TW^T - HA^T||_2$\;
  }

  \BlankLine

  \caption{Алгоритм попеременных неотрицательных наименьших квадратов}
\end{algorithm}

Вместо решения системы линейных алгебраических уранений на каждом шаге,
данный метод решает задачу минимизации $\displaystyle\min_{X \leq 0}||AX - B||_2$, где $A$, $B$ и $X$ - матрицы.
Необходимо обратить внимание на то, что на матрицу $X$ накладывается ограничение неотрицательности,
что позволяет избежать применения шага проецирования матрицы неотрицательную область.
На практике это позволяет значительно повысить скорость сходимости,
онако влечёт за собой увеличение вычислительной сложности алгоритма.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация алгоритма ANNLS на python3, firstline=27, lastline=50]
  {../src/methods/alternating_least_squares.py} \label{code:als_nnls}





\newpage





\section{Алгоритм инициализации матриц $W$ и $H$}

Проблема изложенных алгоритмов неотрицательной матричной факторизации заключается в том,
что сходимость к глобальному минимуму не гарантируется.
Часто случается, что сходимость медленная и достигается неоптимальное приближение.

Эффективная процедура для вычисления хорошего начального приближения может быть основана на сингулярном разложении матрицы $A$.

\begin{algorithm} \label{alg:svd_init}
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKw{KwFrom}{from}

  \BlankLine
  \BlankLine

  \Input{Nonnegative matrix $A$}
  \Output{Nonnegative matrices $W$ и $H$}

  \BlankLine

  Initialize $W$ and $H$ as random dense matrices\;
  Factorize $A$ into $U$, $\Sigma$, $V^T$ using SVD\;
  Set $u_1$ as firts column of $U$\;

  \For{$i$ \KwFrom 1 \KwTo $k$} {
    Compute $C$ as $u_i v_i^T$\;
    Project $C$ to nonnegative space\;
    Factorize $C$ into $U^\prime$, $\Sigma^\prime$, $V^{\prime T}$ using SVD\;
    Set $u^\prime_1$ as $i$-th column of $U$\;
  }

  \BlankLine

  \caption{Алгоритм инициализации матриц $W$ и $H$}
\end{algorithm}

Пусть $A = U \Sigma V^T $ является сингулярным разложением для матрицы $A$,
тогда следует взять первый сингулярный вектор $u_1$ в качестве первого столбца в $W$.
Затем необходимо взять матрицу $C = u_2 v_2^T$ и заменить все её отрицательные элементы на ноль.
Так как $C$ теперь является неотрицательной матрицей, то известно, что первый сингулярный вектор этой матрицы также неотрицательный.
Кроме того, предполагая что это достаточно хорошее приближение $u_2$, возможно принять его за второй столбец $W$.
Продолжим процедуру далее, пока вся матрица $W$ не будет заполнена.

На практике метод даёт хороший прирост к сходимости,
однако с ростом размерности исходной матрицы его использование становится
нецелесообразным из-за большой вычислительной сложности.


\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\begin{lstlisting}[caption=Алгоритм SVD инициализации]
def initialize_svd(A):
  rows, columns = A.shape

  U, _, VT = svd_factorization(A, rank_k)

  W = U[:,:rank_k]
  H = random_matrix(rank_k, columns)

  for j in range(1, rank_k):
    C = reshape(U[:,j], (rows, 1)) @ reshape(VT[j,:], (1, columns))
    C = nonnegative(C)
    u, _, _ = svd_factorization(C, 1)

    W[:,j] = u[:,0]
  return W, H
\end{lstlisting}




\newpage





\section{Сходимость методов решения задачи}

В общем случае, метод неторицательной матричной факторизации любого класса
должен ввести решение в условие оптимальности \cite{chu},
чтобы определить действительно ли это минимум.
Если решение подходит под условия оптимальности, то это означает, что достигнут как минимум локальный минимум.

На самом деле, задача неторицательной матричной факторизации некорректно поставлена,
что означает отсутвие единственного глобального минимума.
Необходимо принять во внимание, что минимальное решение, заданное матрицами $W$ и $H$,
также может быть задано бесконечным числом одинаково хороших пар решений,
таких как $WD$ и $D^{-1}H$, для любых неотрицательных $D$ и $D^{−1}$.
Так как масштабирование и перестановка вызывают проблемы уникальности,
некоторые алгоритмы используют нормализацию строк или столбцов на каждой итерации.

Если в конкретном случае необходимо найти \say{достаточно хороший} локальный минимум,
то можно запустить алгоритм неторицательной матричной факторизации с SVD инициализацией.

\subsubsection{Скорость сходимости}

Доказательство скорости сходимости для этих алгоритмов является открытой нерешённой проблемой.
При определенных условиях возможно говорить о скоростях сходимости выбранных алгоритмов
или сравнивать относительные скорости сходимости между различными алгоритмами.

\subsubsection{Критерий останова}

Для выбора критерия останова необходимо получить оценки качества решения.
Поскольку сингулярое разложение ранга $k$, обозначаемое $U_k \Sigma_k V_k^T$,
обеспечивает нижнюю границу качества, решение должно как минимум удовлетворять следующему неравенству.
\begin{equation*}
  1 - \epsilon \leq \frac{||A - WH||_F}{||A - U_k \Sigma_k V_k^T||_F} \leq 1
\end{equation*}

Где $\epsilon$ - небольшая положительная константа, зависящая от параметров
конкретного алгоритма неторицательной матричной факторизации.

Естественный критерий сходимости $||A - WH||_F$ требует вычислительных затрат,
которые могут быть немного уменьшены при правильной реализации \cite{berry}.
Следующее альтернативное выражение использует свойства нормы, для уменьшения вычислительных затрат.
\begin{equation*}
  ||A - WH||^2_F = trace(A^T A) - 2 trace(H^T (W^T A)) + trace(H^T (W^T W H))
\end{equation*}

Данное выражение содежит эффективный порядок матричных произведений и позволяет
единожды произвести вычисления связанные с $trace(A^T A)$.

Потчи все алгоритмы неотрицательной матричной факторизации используют
максимальное количество итераций, как вторичный критерий останова.
Однако очевидно, что фиксированное количество итераций это не математически верный
подход для контроля итерационного процесса и максимальное количество итераций зависит от конкретной прикладной задачи.

Принимая во внимание всё вышесказанное и необходимость работы с разреженными данными,
воспользуемся критерим останова, основанном на выражении \ref{eq:frob_norm} с некоторыми оговорками.

Для экономии вычислительных ресурсов будем считать норму $f|| A - WH ||_F$ только по неотрицательным элементам матрицы $A$.
\begin{equation*}
  ||A - WH|| = \sum\limits_{i, j: \ A_{ij} > 0}  | A_{ij} - w_i  h^T_j |
\end{equation*}

Запись $w_i h^T_j$ означает скалярное произведение вектора-строки из матрицы $W$ и вектора-столбца из матрицы $H$.

\newpage

Ниже приведена реализация данного алгоритма на языке программирования \textit{Python 3}.
\\

\lstinputlisting
  [caption=Реализация критерия останова, firstline=17, lastline=26]
  {../src/utils.py} \label{code:als_nnls}
